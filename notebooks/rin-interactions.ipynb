{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIN interactions\n",
    "\n",
    "## Summary\n",
    "\n",
    "Protein structures, dynamics and functions are the result of a network of interactions between the residues that constitute them. We call such network *Residue-Interaction Network* (RIN). \n",
    "\n",
    "In this notebook, we obtained the subset of the Nitrogenase RIN that connects the D and the G subunits by using the PROLIF library on extant and ancient structures that we predicted through ColabFold. Our aim is to construct the timeline of the evolution of this interface across time — though mostly focused on the emergence of the interface—\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prolif\n",
    "import MDAnalysis as mda\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import List, Dict\n",
    "from pyfamsa import Aligner, Sequence\n",
    "# import logomaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "import prody as pdy\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import AlignIO\n",
    "import prody as pdy\n",
    "from Bio.SeqUtils import seq1\n",
    "import seaborn as sns\n",
    "from Bio import AlignIO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_structure_sequences(proteins: Dict[str, pdy.AtomGroup], chain):\n",
    "    # TODO: Move this code to a module\n",
    "    \"\"\"\n",
    "    Generates a list of aligned sequences\n",
    "\n",
    "    arguments\n",
    "    ---------\n",
    "    - proteins: List[pdy.AtomGroup]\n",
    "    - chain: str\n",
    "    \n",
    "    \"\"\"\n",
    "    # Align Sequence\n",
    "    sequence_records = []\n",
    "    for key, protein in proteins.items():\n",
    "        sequence_records.append(\n",
    "            Sequence(key.encode(), protein.select(f'chain {chain:s} and name CA').getSequence().encode())\n",
    "        )\n",
    "    \n",
    "    aligner = Aligner()\n",
    "    msa = aligner.align(sequence_records)\n",
    "    # return [dict(id=item.id.decode(), sequence=item.sequence.decode()) for item in msa]\n",
    "    return [[item.id.decode()] + list(item.sequence.decode()) for item in msa]\n",
    "\n",
    "\n",
    "def map_alignment_to_structure(alignment, structures, on_chain):\n",
    "    \"\"\"\n",
    "    Returns a dataframe with the sequence alignment and mappings to its residues\n",
    "\n",
    "    arguments\n",
    "    ---------\n",
    "    - proteins: List[pdy.AtomGroup]\n",
    "    - chain: str\n",
    "\n",
    "    \"\"\"\n",
    "    alignment = pd.DataFrame(alignment).set_index(0).T\n",
    "    for column in alignment.columns:\n",
    "        structure = structures[column]\n",
    "        seq = alignment[column].to_list()\n",
    "        chain = structure.select(f'chain {on_chain:s}').getHierView()\n",
    "        residues = list(chain.iterResidues())\n",
    "        residue_list = []\n",
    "        active = False\n",
    "        for i, pos in enumerate(seq):\n",
    "            if len(residues) == 0:\n",
    "                residue_list.append(None)\n",
    "                continue\n",
    "            \n",
    "            if pos == '-': \n",
    "                residue_list.append(None)\n",
    "                continue\n",
    "            \n",
    "            if pos == residues[0].select('name CA').getSequence():\n",
    "                residue_list.append(residues.pop(0))\n",
    "\n",
    "        if len(residues) > 0:\n",
    "            raise RuntimeError(\"sequence failed to map\")\n",
    "        alignment['map:' + column] = residue_list\n",
    "\n",
    "    return alignment\n",
    "\n",
    "def get_position_entropy(u):\n",
    "    \"\"\"\n",
    "    Useful to compute the entropy of the alignment\n",
    "    \"\"\"\n",
    "    u = np.array(u)\n",
    "    probs = []\n",
    "    for char in np.unique(u):\n",
    "        probs.append(((u == char).sum() / len(u)))\n",
    "    \n",
    "    return entropy(probs, base=2)\n",
    "\n",
    "\n",
    "def get_coord_sets(alignment):\n",
    "    coordinates = []\n",
    "    for column in filter(lambda x: x[:3] == 'map', alignment.columns):\n",
    "        coordinates.append(alignment.query('entropy < 0.01').apply(lambda x: x[column].select('name CA').getCoords().reshape(-1).tolist(), axis=1).to_list())\n",
    "    return np.array(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_network(prmtop, pdb, reference, chain_D, chain_G, label1, label2):\n",
    "    u = mda.Universe(prmtop, pdb)\n",
    "    ref = mda.Universe(reference)\n",
    "    u.add_TopologyAttr('chainID')\n",
    "\n",
    "    for res, res_ref in zip(u.residues, ref.residues):\n",
    "        res.resnum = res_ref.resnum\n",
    "        res.resid = res_ref.resid\n",
    "        for atom in res.atoms:\n",
    "            atom.chainID = np.unique(res_ref.atoms.chainIDs)[0]\n",
    "\n",
    "    chain_D = u.select_atoms(chain_D)\n",
    "    chain_G = u.select_atoms(chain_G)\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    pf = prolif.Fingerprint()\n",
    "    pf.run(u.trajectory, chain_D, chain_G)\n",
    "\n",
    "    for record in pf.to_dataframe().T.to_records():\n",
    "        label_1 = label1 + '.' + record[0].replace('HIE', 'HIS')\n",
    "        chain_1 = record[0].split('.')[1]\n",
    "        residue_1 = record[0].split('.')[0].replace('HIE', 'HIS')\n",
    "        positions_1 = u.select_atoms(f'chainid {chain_1} and resnum {residue_1[3:]} and name CA').positions\n",
    "\n",
    "        label_2 = label2 + '.' + record[1].replace('HIE', 'HIS')\n",
    "        chain_2 = record[1].split('.')[1]\n",
    "        residue_2 = record[1].split('.')[0].replace('HIE', 'HIS')\n",
    "        positions_2 = u.select_atoms(f'chainid {chain_2} and resnum {residue_2[3:]} and name CA').positions\n",
    "\n",
    "\n",
    "        G.add_node(label_1, chain=chain_1, residue=residue_1, positions=positions_1)\n",
    "        G.add_node(label_2, chain=chain_2, residue=residue_2, positions=positions_2)\n",
    "        G.add_edge(label_1, label_2, type=record[2])\n",
    "\n",
    "    return G, pf\n",
    "\n",
    "restype = dict(\n",
    "    ALA = \"apolar\",\n",
    "    CYS = \"polar\",\n",
    "    ASP = \"negative\",\n",
    "    GLU = \"negative\",\n",
    "    PHE = \"apolar\",\n",
    "    GLY = \"polar\",\n",
    "    HIS = \"positive\",\n",
    "    HIE = \"positive\",\n",
    "    ILE = \"apolar\",\n",
    "    LYS = \"positive\",\n",
    "    LEU = \"apolar\",\n",
    "    MET = \"apolar\",\n",
    "    ASN = \"very_polar\",\n",
    "    PRO = \"apolar\",\n",
    "    GLN = \"very_polar\",\n",
    "    ARG = \"positive\",\n",
    "    SER = \"polar\",\n",
    "    THR = \"polar\",\n",
    "    VAL = \"apolar\",\n",
    "    TRP = \"bulky\",\n",
    "    TYR = \"polar\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution of the interface"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Alignment\n",
    "\n",
    "One of the main issues we face is that residues change their numbering during evolution due to insertions and deletions. We map all the proteins that we use to a common dataframe after aligning their sequences, so we skip this problem. **This data will be used in other analysis!**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D subunit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    'DK.Anc265', 'DK.Anc264', 'DKG.Anc262', 'DKG.Anc263','DKG.Anc330', 'DKG.AzoV.Anf.pdb','DKG.AzoV.Vnf'\n",
    "]\n",
    "structures = dict((file, pdy.parsePDB(f'../data/surface-network/{file:s}.aligned.pdb')) for file in files)\n",
    "alignment = align_structure_sequences(structures, chain='A')\n",
    "u = map_alignment_to_structure(alignment, structures, 'A')\n",
    "seq_columns = [col for col in u.columns if col[:3] != 'map']\n",
    "u['entropy'] = u[seq_columns].apply(lambda x: get_position_entropy(x), axis=1)\n",
    "# alignment_coordinates = get_coord_sets(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G subunit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    'DKG.Anc262', 'DKG.Anc263','DKG.Anc330', 'DKG.AzoV.Anf.pdb','DKG.AzoV.Vnf'\n",
    "]\n",
    "structures = dict((file, pdy.parsePDB(f'../data/surface-network/{file:s}.aligned.pdb')) for file in files)\n",
    "alignment = align_structure_sequences(structures, chain='C')\n",
    "v = map_alignment_to_structure(alignment, structures, 'C')\n",
    "seq_columns = [col for col in v.columns if col[:3] != 'map']\n",
    "v['entropy'] = v[seq_columns].apply(lambda x: get_position_entropy(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping Residues D subunit\n",
    "u['resnum:AzoV.Vnf'] = u['map:DKG.AzoV.Vnf'].apply(lambda x: int(x.select('name CA').getResnums()[0]) if x is not None else None).astype(int, errors='ignore')\n",
    "u['resnum:AzoV.Anf'] = u['map:DKG.AzoV.Anf.pdb'].apply(lambda x: int(x.select('name CA').getResnums()[0]) if x is not None else None).astype(int, errors='ignore')\n",
    "u['resnum:Anc262'] = u['map:DKG.Anc262'].apply(lambda x: int(x.select('name CA').getResnums()[0]) if x is not None else None).astype(int, errors='ignore')\n",
    "u['resnum:Anc263'] = u['map:DKG.Anc263'].apply(lambda x: int(x.select('name CA').getResnums()[0]) if x is not None else None).astype(int, errors='ignore')\n",
    "u['resnum:Anc330'] = u['map:DKG.Anc330'].apply(lambda x: int(x.select('name CA').getResnums()[0]) if x is not None else None).astype(int, errors='ignore')\n",
    "u['resnum:Anc265'] = u['map:DK.Anc265'].apply(lambda x: int(x.select('name CA').getResnums()[0]) if x is not None else None).astype(int, errors='ignore')\n",
    "u['resnum:Anc264'] = u['map:DK.Anc264'].apply(lambda x: int(x.select('name CA').getResnums()[0]) if x is not None else None).astype(int, errors='ignore')\n",
    "# Mapping Residues G subunit\n",
    "v['resnum:AzoV.Vnf'] = v['map:DKG.AzoV.Vnf'].apply(lambda x: int(x.select('name CA').getResnums()[0]) if x is not None else None).astype(int, errors='ignore')\n",
    "v['resnum:AzoV.Anf'] = v['map:DKG.AzoV.Anf.pdb'].apply(lambda x: int(x.select('name CA').getResnums()[0]) if x is not None else None).astype(int, errors='ignore')\n",
    "v['resnum:Anc262'] = v['map:DKG.Anc262'].apply(lambda x: int(x.select('name CA').getResnums()[0]) if x is not None else None).astype(int, errors='ignore')\n",
    "v['resnum:Anc263'] = v['map:DKG.Anc263'].apply(lambda x: int(x.select('name CA').getResnums()[0]) if x is not None else None).astype(int, errors='ignore')\n",
    "v['resnum:Anc330'] = v['map:DKG.Anc330'].apply(lambda x: int(x.select('name CA').getResnums()[0]) if x is not None else None).astype(int, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_values_u = pd.read_csv('../data/signatures/signatures.csv').query('chain == \"A\"').rename(columns={\"residue\": \"resnum:AzoV.Vnf\"})\n",
    "signature_values_v = pd.read_csv('../data/signatures/signatures.csv').query('chain == \"C\"').rename(columns={\"residue\": \"resnum:AzoV.Vnf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = pd.merge(u, signature_values_u, on='resnum:AzoV.Vnf', how='inner')\n",
    "v = pd.merge(v, signature_values_v, on='resnum:AzoV.Vnf', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc262_files = (\n",
    "    '../data/surface-network/DKG.Anc262.aligned.prmtop', \n",
    "    '../data/surface-network/DKG.Anc262.aligned.inpcrd', \n",
    "    '../data/surface-network/DKG.Anc262.aligned.pdb', 'chainid A', 'chainid C', 'Anc262', 'Anc262'\n",
    ")\n",
    "\n",
    "anc263_files = (\n",
    "    '../data/surface-network/DKG.Anc263.aligned.prmtop', \n",
    "    '../data/surface-network/DKG.Anc263.aligned.inpcrd', \n",
    "    '../data/surface-network/DKG.Anc263.aligned.pdb', 'chainid A', 'chainid C', 'Anc263', 'Anc263'\n",
    ")\n",
    "\n",
    "anc330_files = (\n",
    "    '../data/surface-network/DKG.Anc330.aligned.prmtop', \n",
    "    '../data/surface-network/DKG.Anc330.aligned.inpcrd', \n",
    "    '../data/surface-network/DKG.Anc330.aligned.pdb', 'chainid A', 'chainid C', 'Anc330', 'Anc330'\n",
    ")\n",
    "azov_vnf = (\n",
    "    '../data/surface-network/DKG.AzoV.Vnf.aligned.prmtop', \n",
    "    '../data/surface-network/DKG.AzoV.Vnf.aligned.inpcrd', \n",
    "    '../data/surface-network/DKG.AzoV.Vnf.aligned.pdb', 'chainid A', 'chainid C', 'AzoV.Vnf', 'AzoV.Vnf'\n",
    ")\n",
    "\n",
    "azov_anf = (\n",
    "    '../data/surface-network/DKG.AzoV.Anf.aligned.prmtop', \n",
    "    '../data/surface-network/DKG.AzoV.Anf.aligned.inpcrd', \n",
    "    '../data/surface-network/DKG.AzoV.Anf.pdb.aligned.pdb', 'chainid A', 'chainid C', 'AzoV.Anf', 'AzoV.Anf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/home/bcz/miniconda3/envs/gsubunit/lib/python3.9/multiprocessing/reduction.py:51: UserWarning: Reader has no dt information, set to 1.0 ps\n",
      "  cls(buf, protocol).dump(obj)\n",
      "/home/bcz/miniconda3/envs/gsubunit/lib/python3.9/site-packages/MDAnalysis/converters/RDKit.py:990: UserWarning: The standardization could not be completed within a reasonable number of iterations\n",
      "  warnings.warn(\"The standardization could not be completed within a \"\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.11s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]/home/bcz/miniconda3/envs/gsubunit/lib/python3.9/multiprocessing/reduction.py:51: UserWarning: Reader has no dt information, set to 1.0 ps\n",
      "  cls(buf, protocol).dump(obj)\n",
      "/home/bcz/miniconda3/envs/gsubunit/lib/python3.9/site-packages/MDAnalysis/converters/RDKit.py:990: UserWarning: The standardization could not be completed within a reasonable number of iterations\n",
      "  warnings.warn(\"The standardization could not be completed within a \"\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.12s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]/home/bcz/miniconda3/envs/gsubunit/lib/python3.9/multiprocessing/reduction.py:51: UserWarning: Reader has no dt information, set to 1.0 ps\n",
      "  cls(buf, protocol).dump(obj)\n",
      "/home/bcz/miniconda3/envs/gsubunit/lib/python3.9/site-packages/MDAnalysis/converters/RDKit.py:990: UserWarning: The standardization could not be completed within a reasonable number of iterations\n",
      "  warnings.warn(\"The standardization could not be completed within a \"\n",
      "100%|██████████| 1/1 [00:23<00:00, 23.14s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]/home/bcz/miniconda3/envs/gsubunit/lib/python3.9/multiprocessing/reduction.py:51: UserWarning: Reader has no dt information, set to 1.0 ps\n",
      "  cls(buf, protocol).dump(obj)\n",
      "/home/bcz/miniconda3/envs/gsubunit/lib/python3.9/site-packages/MDAnalysis/converters/RDKit.py:990: UserWarning: The standardization could not be completed within a reasonable number of iterations\n",
      "  warnings.warn(\"The standardization could not be completed within a \"\n",
      "100%|██████████| 1/1 [00:21<00:00, 21.14s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]/home/bcz/miniconda3/envs/gsubunit/lib/python3.9/multiprocessing/reduction.py:51: UserWarning: Reader has no dt information, set to 1.0 ps\n",
      "  cls(buf, protocol).dump(obj)\n",
      "/home/bcz/miniconda3/envs/gsubunit/lib/python3.9/site-packages/MDAnalysis/converters/RDKit.py:990: UserWarning: The standardization could not be completed within a reasonable number of iterations\n",
      "  warnings.warn(\"The standardization could not be completed within a \"\n"
     ]
    }
   ],
   "source": [
    "anc262_network_original, anc262_df = generate_network(*anc262_files)\n",
    "anc263_network_original, anc263_df = generate_network(*anc263_files)\n",
    "anc330_network_original, anc330_df = generate_network(*anc330_files)\n",
    "azov_vnf_network_original, azov_vnf_df = generate_network(*azov_vnf)\n",
    "azov_anf_network_original, azov_anf_df = generate_network(*azov_anf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc262_network = anc262_network_original.copy()\n",
    "anc263_network = anc263_network_original.copy()\n",
    "anc330_network = anc330_network_original.copy()\n",
    "azov_vnf_network = azov_vnf_network_original.copy()\n",
    "azov_anf_network = azov_anf_network_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "azov_vnf_d_residues = [int(item[0].split('.')[0][3:]) for item in azov_vnf_df.to_dataframe().T.index]\n",
    "azov_anf_d_residues = [int(item[0].split('.')[0][3:]) for item in azov_anf_df.to_dataframe().T.index]\n",
    "anc262_d_residues = [int(item[0].split('.')[0][3:]) for item in anc262_df.to_dataframe().T.index]\n",
    "anc263_d_residues = [int(item[0].split('.')[0][3:]) for item in anc263_df.to_dataframe().T.index]\n",
    "anc330_d_residues = [int(item[0].split('.')[0][3:]) for item in anc330_df.to_dataframe().T.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:34<00:00, 34.14s/it]"
     ]
    }
   ],
   "source": [
    "azov_vnf_g_residues = [int(item[1].split('.')[0][3:]) for item in azov_vnf_df.to_dataframe().T.index]\n",
    "azov_anf_g_residues = [int(item[1].split('.')[0][3:]) for item in azov_anf_df.to_dataframe().T.index]\n",
    "anc262_g_residues = [int(item[1].split('.')[0][3:]) for item in anc262_df.to_dataframe().T.index]\n",
    "anc263_g_residues = [int(item[1].split('.')[0][3:]) for item in anc263_df.to_dataframe().T.index]\n",
    "anc330_g_residues = [int(item[1].split('.')[0][3:]) for item in anc330_df.to_dataframe().T.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Decomposition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RINs will be visualized with tools for network analysis. Those usually consider 2D planes to visualize data. Given that we want to compare the networks among them, have a certain spatial feeling and represent as much data as possible, applying a Principal Component Analysis decomposition in the 3D coordinates of all the interface residues is the easiest path to comply with our three goals. We use the PCs of one of our systems and we apply it to all our other systems. *Note that our structures were previously aligned*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_positions = []\n",
    "for node, node_data in azov_vnf_network.nodes(data=True):\n",
    "    try:\n",
    "        ref_positions.append(node_data['positions'])\n",
    "    except KeyError:\n",
    "        print(f\"problem with {node}\")\n",
    "\n",
    "\n",
    "ref_positions = np.concatenate(ref_positions, axis=0)\n",
    "ref_positions = StandardScaler().fit_transform(ref_positions)\n",
    "pca = PCA(3).fit(ref_positions)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "for network in [anc263_network, anc262_network, anc330_network, azov_vnf_network, azov_anf_network]:\n",
    "    positions = []\n",
    "    for node, node_data in network.nodes(data=True):\n",
    "        positions.append(node_data['positions'])\n",
    "    positions = np.concatenate(positions, axis=0)\n",
    "    positions = StandardScaler().fit_transform(positions)\n",
    "    positions = pca.transform(positions)\n",
    "\n",
    "    for (node, node_data), position in zip(network.nodes(data=True), positions):\n",
    "        node_data['pos_x'] = float(position[0])\n",
    "        node_data['pos_y'] = float(position[1])\n",
    "        node_data['residue_label'] = node_data['residue'][:3]\n",
    "        del node_data['positions']        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network in [anc263_network, anc262_network, anc330_network, azov_vnf_network, azov_anf_network]:\n",
    "    for node, node_data in network.nodes(data=True):\n",
    "        node_data['residue_type'] = restype[node_data['residue_label']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Networks to the sequence alignment\n",
    "\n",
    "By doing this, we will be able to have a global picture of which residues are at the interface in each of the systems, and we will be able to generate a global interface list — even when there is not G subunit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 20)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u['interface'] = False\n",
    "u.loc[u['resnum:AzoV.Vnf'].isin(pd.unique(azov_vnf_d_residues)),'interface'] = True\n",
    "u.loc[u['resnum:AzoV.Anf'].isin(pd.unique(azov_anf_d_residues)),'interface'] = True\n",
    "u.loc[u['resnum:Anc262'].isin(pd.unique(anc262_d_residues)),'interface'] = True\n",
    "u.loc[u['resnum:Anc263'].isin(pd.unique(anc263_d_residues)),'interface'] = True\n",
    "u.loc[u['resnum:Anc330'].isin(pd.unique(anc330_d_residues)),'interface'] = True\n",
    "u.query('interface == True').shape\n",
    "#alignment = AlignIO.read(open(\"../data/surface-network/D_Align.fasta\"), \"fasta\")\n",
    "\n",
    "v['interface'] = False\n",
    "v.loc[v['resnum:AzoV.Vnf'].isin(pd.unique(azov_vnf_g_residues)),'interface'] = True\n",
    "v.loc[v['resnum:AzoV.Anf'].isin(pd.unique(azov_anf_g_residues)),'interface'] = True\n",
    "v.loc[v['resnum:Anc262'].isin(pd.unique(anc262_g_residues)),'interface'] = True\n",
    "v.loc[v['resnum:Anc263'].isin(pd.unique(anc263_g_residues)),'interface'] = True\n",
    "v.loc[v['resnum:Anc330'].isin(pd.unique(anc330_g_residues)),'interface'] = True\n",
    "v.query('interface == True').shape\n",
    "#alignment = AlignIO.read(open(\"../data/surface-network/D_Align.fasta\"), \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_index(series, label, chain):\n",
    "    out = []\n",
    "    for item in series:\n",
    "        if item is None:\n",
    "            out.append(None)\n",
    "        else:\n",
    "            resnum = item.getResnum()\n",
    "            restype = item.getResname()\n",
    "            out.append(label + '.{:s}{:d}'.format(restype, resnum) + '.' + chain)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "u['index:Anc265'] = generate_index(u['map:DK.Anc265'], 'Anc265', 'A')\n",
    "u['index:Anc264'] = generate_index(u['map:DK.Anc264'], 'Anc264', 'A')\n",
    "u['index:Anc263'] = generate_index(u['map:DKG.Anc263'], 'Anc263', 'A')\n",
    "u['index:Anc262'] = generate_index(u['map:DKG.Anc262'], 'Anc262', 'A')\n",
    "u['index:Anc330'] = generate_index(u['map:DKG.Anc330'], 'Anc330', 'A')\n",
    "u['index:AzoV.Anf'] = generate_index(u['map:DKG.AzoV.Anf.pdb'], 'AzoV.Anf', 'A')\n",
    "u['index:AzoV.Vnf'] = generate_index(u['map:DKG.AzoV.Vnf'], 'AzoV.Vnf', 'A')\n",
    "\n",
    "v['index:Anc263'] = generate_index(v['map:DKG.Anc263'], 'Anc263', 'C')\n",
    "v['index:Anc262'] = generate_index(v['map:DKG.Anc262'], 'Anc262', 'C')\n",
    "v['index:Anc330'] = generate_index(v['map:DKG.Anc330'], 'Anc330', 'C')\n",
    "v['index:AzoV.Anf'] = generate_index(v['map:DKG.AzoV.Anf.pdb'], 'AzoV.Anf', 'C')\n",
    "v['index:AzoV.Vnf'] = generate_index(v['map:DKG.AzoV.Vnf'], 'AzoV.Vnf', 'C')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save here the D and G aligned residue tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.to_csv('../data/surface-network/D.subunit.csv')\n",
    "v.to_csv('../data/surface-network/G.subunit.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Including non-interacting residues in RINs\n",
    "\n",
    "This step is aimed to make all networks uniform. Some of our systems, as Anc264 don't even have a small subunit, so the interface doesn't exist. However, we might still be interested in comparing the regions of the protein surface that could have participated in the interaction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc264_ni_network = nx.DiGraph()\n",
    "for index, item in u.query('interface == True')['map:DK.Anc264'].items():\n",
    "    if item is None: continue\n",
    "    label = 'Anc264' + '.' + item.getResname() + '{:d}'.format(item.getResnum()) + '.A'\n",
    "    anc264_ni_network.add_node(\n",
    "        label, chain='A', residue=item.getResname().replace('HIE', 'HIS'), positions=item.select('name CA').getCoords()\n",
    "    )\n",
    "\n",
    "\n",
    "anc265_ni_network = nx.DiGraph()\n",
    "for index, item in u.query('interface == True')['map:DK.Anc265'].items():\n",
    "    if item is None: continue\n",
    "    label = 'Anc265' + '.' + item.getResname() + '{:d}'.format(item.getResnum()) + '.A'\n",
    "    anc265_ni_network.add_node(\n",
    "        label, chain='A', residue=item.getResname().replace('HIE', 'HIS'), positions=item.select('name CA').getCoords()\n",
    "    )\n",
    "\n",
    "anc263_ni_network = nx.DiGraph()\n",
    "for index, item in u.query('interface == True')['map:DKG.Anc263'].items():\n",
    "    if item is None: continue\n",
    "    label = 'Anc263' + '.' + item.getResname() + '{:d}'.format(item.getResnum()) + '.A'\n",
    "    anc263_ni_network.add_node(\n",
    "        label, chain='A', residue=item.getResname().replace('HIE', 'HIS'), positions=item.select('name CA').getCoords()\n",
    "    )\n",
    "\n",
    "for index, item in v.query('interface == True')['map:DKG.Anc263'].items():\n",
    "    if item is None: continue\n",
    "    label = 'Anc263' + '.' + item.getResname() + '{:d}'.format(item.getResnum()) + '.C'\n",
    "    anc263_ni_network.add_node(\n",
    "        label, chain='C', residue=item.getResname().replace('HIE', 'HIS'), positions=item.select('name CA').getCoords()\n",
    "    )\n",
    "\n",
    "\n",
    "anc262_ni_network = nx.DiGraph()\n",
    "for index, item in u.query('interface == True')['map:DKG.Anc262'].items():\n",
    "    if item is None: continue\n",
    "    label = 'Anc262' + '.' + item.getResname() + '{:d}'.format(item.getResnum()) + '.A'\n",
    "    anc262_ni_network.add_node(\n",
    "        label, chain='A', residue=item.getResname().replace('HIE', 'HIS'), positions=item.select('name CA').getCoords()\n",
    "    )\n",
    "\n",
    "anc330_ni_network = nx.DiGraph()\n",
    "for index, item in u.query('interface == True')['map:DKG.Anc330'].items():\n",
    "    if item is None: continue\n",
    "    label = 'Anc330' + '.' + item.getResname() + '{:d}'.format(item.getResnum()) + '.A'\n",
    "    anc330_ni_network.add_node(\n",
    "        label, chain='A', residue=item.getResname().replace('HIE', 'HIS'), positions=item.select('name CA').getCoords()\n",
    "    )\n",
    "\n",
    "azov_vnf_ni_network = nx.DiGraph()\n",
    "for index, item in u.query('interface == True')['map:DKG.AzoV.Vnf'].items():\n",
    "    if item is None: continue\n",
    "    label = 'AzoV.Vnf' + '.' + item.getResname().replace('HIE', 'HIS') + '{:d}'.format(item.getResnum()) + '.A'\n",
    "    azov_vnf_ni_network.add_node(\n",
    "        label, chain='A', residue=item.getResname().replace('HIE', 'HIS'), positions=item.select('name CA').getCoords()\n",
    "    )\n",
    "\n",
    "azov_anf_ni_network = nx.DiGraph()\n",
    "for index, item in u.query('interface == True')['map:DKG.AzoV.Anf.pdb'].items():\n",
    "    if item is None: continue\n",
    "    label = 'AzoV.Anf' + '.' + item.getResname().replace('HIE', 'HIS') + '{:d}'.format(item.getResnum()) + '.A'\n",
    "    azov_anf_ni_network.add_node(\n",
    "        label, chain='A', residue=item.getResname(), positions=item.select('name CA').getCoords()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "for network in [anc265_ni_network, anc264_ni_network,anc263_ni_network,anc262_ni_network,anc330_ni_network,azov_vnf_ni_network,azov_anf_ni_network]:\n",
    "    positions = []\n",
    "    for node, node_data in network.nodes(data=True):\n",
    "        positions.append(node_data['positions'])\n",
    "    positions = np.concatenate(positions, axis=0)\n",
    "    positions = StandardScaler().fit_transform(positions)\n",
    "    positions = pca.transform(positions)\n",
    "\n",
    "    for (node, node_data), position in zip(network.nodes(data=True), positions):\n",
    "        node_data['pos_x'] = float(position[0])\n",
    "        node_data['pos_y'] = float(position[1])\n",
    "        node_data['residue'] = node.split('.')[-2]\n",
    "        node_data['residue_label'] = node_data['residue'][:3]\n",
    "        node_data['residue_type'] = restype[node_data['residue_label']]\n",
    "        del node_data['positions']        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Composing the final networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc265_network = anc265_ni_network.copy()\n",
    "anc264_network = anc264_ni_network.copy()\n",
    "anc263_network = nx.compose_all([anc263_ni_network, anc263_network])\n",
    "anc262_network = nx.compose_all([anc262_ni_network, anc262_network])\n",
    "anc330_network = nx.compose_all([anc330_ni_network, anc330_network])\n",
    "azov_vnf_network = nx.compose_all([azov_vnf_ni_network, azov_vnf_network])\n",
    "azov_anf_network = nx.compose_all([azov_anf_ni_network, azov_anf_network])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#u['resnum:AzoV.Vnf'] = u['map:DKG.AzoV.Vnf'].apply(lambda x: x.getResnum())\n",
    "#u['resnum:AzoV.Vnf'] = u['map:DKG.AzoV.Vnf'].apply(lambda x: x.getResnum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign some more information that will be useful for our visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:35<00:00, 35.14s/it]\n"
     ]
    }
   ],
   "source": [
    "for network, column in [\n",
    "    (anc265_network, 'index:Anc265'), (anc264_network, 'index:Anc264'),\n",
    "    (anc263_network, 'index:Anc263'), (anc262_network, 'index:Anc262'), (anc330_network, 'index:Anc330'), \n",
    "    (azov_vnf_network, 'index:AzoV.Vnf'), (azov_anf_network, 'index:AzoV.Anf')]:\n",
    "    for node, node_data in network.nodes(data=True):\n",
    "        if node_data['chain'] == \"C\": \n",
    "            aln_ref = v\n",
    "        else:\n",
    "            aln_ref = u\n",
    "\n",
    "        try:\n",
    "            item = aln_ref.reset_index().set_index(column).loc[node]\n",
    "        except KeyError:\n",
    "            item = aln_ref.reset_index().set_index(column).loc[node.replace('HIE', 'HIS')]\n",
    "        node_data['aln_position'] = int(item['resnum:AzoV.Vnf'])\n",
    "        node_data['res'] = seq1(node_data['residue'][:3].replace('HIE', 'HIS'))\n",
    "\n",
    "        node_data['cool_name'] = node_data['res'] + '{:d}'.format(node_data['aln_position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gml(anc265_network, '../data/surface-network/anc265.gml')\n",
    "nx.write_gml(anc264_network, '../data/surface-network/anc264.gml')\n",
    "nx.write_gml(anc263_network, '../data/surface-network/anc263.gml')\n",
    "nx.write_gml(anc262_network, '../data/surface-network/anc262.gml')\n",
    "nx.write_gml(anc330_network, '../data/surface-network/anc330.gml')\n",
    "nx.write_gml(azov_vnf_network, '../data/surface-network/AzoV.Vnf.gml')\n",
    "nx.write_gml(azov_anf_network, '../data/surface-network/AzoV.Anf.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_level(network, level):\n",
    "\n",
    "    for node, node_data in network.nodes(data=True):\n",
    "        node_data['level'] = level\n",
    "    return network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Networks with our networks stacked according to their evolutionary timeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc264_network = add_level(anc264_network, level=0)\n",
    "anc263_network = add_level(anc263_network, level=1)\n",
    "anc262_network = add_level(anc262_network, level=2)\n",
    "azov_vnf_network = add_level(azov_vnf_network, level=3)\n",
    "stacked = nx.compose_all([anc264_network, anc263_network, anc262_network, azov_vnf_network])\n",
    "nx.write_gml(stacked, '../data/surface-network/stacked.vnf.gml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc263_network = add_level(anc263_network, level=1)\n",
    "anc262_network = add_level(anc330_network, level=2)\n",
    "azov_vnf_network = add_level(azov_anf_network, level=3)\n",
    "stacked = nx.compose_all([anc263_network, anc330_network, azov_anf_network])\n",
    "nx.write_gml(stacked, '../data/surface-network/stacked.anf.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_interface = u.query('interface == True')[['DK.Anc265','DK.Anc264','DKG.Anc263','DKG.Anc262','DKG.Anc330','DKG.AzoV.Vnf', 'DKG.AzoV.Anf.pdb']].values.T.tolist()\n",
    "seq_interface = '\\n'.join([''.join(i) for i in seq_interface])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing interface alignments. These sequences don't represent the sequences but the residues that make those interfaces, devoid of any order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENLCNHLRTYQMKEGPYIRSEQKREKFEWHK-HEDEKAR\n",
      "DTNLCNHLRTYQMKEGPYIKDEYEREKFEWHK-HEDEKAR\n",
      "DTTLSNHLRGYNEKKGPRLDDDYERKAFEWHKDHQEEKAR\n",
      "DTTLSNHLRGYNEKKGPRLDDDYERKAFEWHKDHQEEKAR\n",
      "DLTLGYHLREYNERKGPRLDDDLEMKMFEWHHEHQGEKAR\n",
      "DTRLANHLRGYNEKKGPRLDDNYERKAFEWHKDHEEEKAR\n",
      "TLALGYHLREYNERVGPRLDDKPDRKMFEWHHEHQGEKAR\n"
     ]
    }
   ],
   "source": [
    "print(seq_interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 25,  26,  27,  30,  33,  34, 179, 250, 257, 260, 261, 264, 265,\n",
       "            267, 268, 271, 273, 274, 275, 276, 278, 283, 284, 287, 290, 291,\n",
       "            294, 295, 299, 339, 340, 343, 347, 362, 363, 364, 367, 368, 371,\n",
       "            372],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.query('interface == True').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_interface = v.query('interface == True')[['DKG.Anc263','DKG.Anc262','DKG.Anc330','DKG.AzoV.Vnf', 'DKG.AzoV.Anf.pdb']].values.T.tolist()\n",
    "seq_interface = '\\n'.join([''.join(i) for i in seq_interface])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QERLFYSDRELPQRCYADKIADKRDIKSLNEEY\n",
      "QERLFYSDREMPQRCYADKIADKRDIKSLNEEY\n",
      "MKRLFHSDRRLPARCWVDVVNGRRYLKSLNQEY\n",
      "EERLFFSDRERPQRLYADLANDERDVRSTNREY\n",
      "MKNLFHSDRRLSHRCWVDVCDDERYLGSLNEEY\n"
     ]
    }
   ],
   "source": [
    "print(seq_interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14,  15,  16,  18,  21,  22,  23,  27,  28,  30,  50,  53,  54,\n",
       "        56,  57,  59,  60,  61,  63,  64,  67,  68,  71,  94,  97,  98,\n",
       "       102, 103, 104, 105, 106, 107, 113])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.query('interface == True')['resnum:AzoV.Vnf'].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed49d9dc8263e20f82ef1c732e49d95838d00d7e343ec27a75bb1597d6166618"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('bst')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
